{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:55:03.175971Z",
     "start_time": "2018-12-02T15:55:03.171311Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Input,LSTM,Dense,CuDNNLSTM,Bidirectional\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam,rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:55:04.750419Z",
     "start_time": "2018-12-02T15:55:04.691149Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t嗨。\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hi.</td>\n",
       "      <td>\\t你好。\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Run.</td>\n",
       "      <td>\\t你用跑的。\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wait!</td>\n",
       "      <td>\\t等等！\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hello!</td>\n",
       "      <td>\\t你好。\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   inputs    targets\n",
       "0     Hi.     \\t嗨。\\n\n",
       "1     Hi.    \\t你好。\\n\n",
       "2    Run.  \\t你用跑的。\\n\n",
       "3   Wait!    \\t等等！\\n\n",
       "4  Hello!    \\t你好。\\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/cmn.txt'\n",
    "df = pd.read_table(data_path,header=None)\n",
    "df.columns=['inputs','targets']\n",
    "\n",
    "#讲每句中文句首加上'\\t'作为起始标志，句末加上'\\n'作为终止标志\n",
    "df['targets'] = df['targets'].apply(lambda x: '\\t'+x+'\\n')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:55:06.167721Z",
     "start_time": "2018-12-02T15:55:05.279696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input texts samples\" 20294\n",
      "last 5 character of input text: ['x', 'y', 'z', 'é', '’']\n",
      "last 5 character of target text: ['，', '－', '：', '？', '𡡡']\n"
     ]
    }
   ],
   "source": [
    "input_texts = df.inputs.values.tolist()#英文句子列表\n",
    "target_texts = df.targets.values.tolist()#中文句子列表\n",
    "print('input texts samples\" {}'.format(len(input_texts)))\n",
    "\n",
    "#确定中英文各自包含的字符。df.unique()直接取sum可将unique数组中的各个句子拼接成一个长句子\n",
    "input_characters = sorted(list(set(df.inputs.unique().sum())))\n",
    "target_characters = sorted(list(set(df.targets.unique().sum())))\n",
    "\n",
    "print('last 5 character of input text: {}'.format(input_characters[-5:]))\n",
    "print('last 5 character of target text: {}'.format(target_characters[-5:]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每条句子经过对字母转换成one-hot编码后，生成了LSTM需要的三维输入[n_samples, timestamp, one-hot feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:55:06.187851Z",
     "start_time": "2018-12-02T15:55:06.169915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_SAMPLES: 20294\n",
      "INPUT_LENGTH: 163\n",
      "OUTPUT_LENGTH: 46\n",
      "INPUT_FEATURE_LENGTH: 75\n",
      "OUTPUT_FEATURE_LENGTH: 3427\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "NUM_SAMPLES，样本条数，这里是输入的句子条数\n",
    "INPUT_LENGTH，输入数据的时刻t的长度，这里为最长的英文句子长度\n",
    "OUTPUT_LENGTH，输出数据的时刻t的长度，这里为最长的中文句子长度\n",
    "INPUT_FEATURE_LENGTH，每个时刻进入encoder的lstm单元的数据x t  xtx_t的维度，这里为英文中出现的字符数\n",
    "OUTPUT_FEATURE_LENGTH，每个时刻进入decoder的lstm单元的数据x t  xtx_t的维度，这里为中文中出现的字符数\n",
    "\"\"\"\n",
    "NUM_SAMPLES = len(target_texts)\n",
    "INPUT_LENGTH = max(df.inputs.apply(lambda x: len(x)))\n",
    "OUTPUT_LENGTH = max(df.targets.apply(lambda x: len(x)))\n",
    "INPUT_FEATURE_LENGTH = len(input_characters)\n",
    "OUTPUT_FEATURE_LENGTH = len(target_characters)\n",
    "print('NUM_SAMPLES: {}'.format(NUM_SAMPLES))\n",
    "print('INPUT_LENGTH: {}'.format(INPUT_LENGTH))\n",
    "print('OUTPUT_LENGTH: {}'.format(OUTPUT_LENGTH))\n",
    "print('INPUT_FEATURE_LENGTH: {}'.format(INPUT_FEATURE_LENGTH))\n",
    "print('OUTPUT_FEATURE_LENGTH: {}'.format(OUTPUT_FEATURE_LENGTH))\n",
    "\n",
    "#encoder输入、decoder输入输出初始化为三维向量\n",
    "encoder_input = np.zeros((NUM_SAMPLES,INPUT_LENGTH,INPUT_FEATURE_LENGTH))\n",
    "decoder_input = np.zeros((NUM_SAMPLES,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH))\n",
    "decoder_output = np.zeros((NUM_SAMPLES,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH))\n",
    "\n",
    "\n",
    "input_dict = {char:index for index,char in enumerate(input_characters)}\n",
    "input_dict_reverse = {index:char for index,char in enumerate(input_characters)}\n",
    "target_dict = {char:index for index,char in enumerate(target_characters)}\n",
    "target_dict_reverse = {index:char for index,char in enumerate(target_characters)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T19:10:27.267091Z",
     "start_time": "2018-12-01T19:10:27.261999Z"
    }
   },
   "source": [
    "# 对句子进行字符级one-hot编码，将输入输出数据向量化："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 1: paddle at the end of a scentence ? vs paddle at the beginning of a scentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:55:06.747700Z",
     "start_time": "2018-12-02T15:55:06.475018Z"
    }
   },
   "outputs": [],
   "source": [
    "#encoder的输入向量one-hot\n",
    "for seq_index,seq in enumerate(input_texts):\n",
    "    for char_index, char in enumerate(seq):\n",
    "        encoder_input[seq_index,char_index,input_dict[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# question 2: decoder_input char_index starts from 0, should not be 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:55:08.202067Z",
     "start_time": "2018-12-02T15:55:07.575354Z"
    }
   },
   "outputs": [],
   "source": [
    "#decoder的输入输出向量one-hot，训练模型时decoder的输入要比输出晚一个时间步，这样才能对输出监督\n",
    "for seq_index,seq in enumerate(target_texts):\n",
    "    for char_index,char in enumerate(seq):\n",
    "        decoder_input[seq_index,char_index,target_dict[char]] = 1.0\n",
    "        if char_index > 0:\n",
    "            decoder_output[seq_index,char_index-1,target_dict[char]] = 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T15:55:13.382946Z",
     "start_time": "2018-12-02T15:55:13.372019Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(n_input,n_output,n_units):\n",
    "    \"\"\"\n",
    "    n_input: encoder输入维度n_input为每个时间步的输入xt的维度，这里是用来one-hot的英文字符数\n",
    "    n_output: decoder的输入维度为中文字符数\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    #训练阶段\n",
    "    encoder_input = Input(shape = (None, n_input))\n",
    "    encoder = CuDNNLSTM(n_units, return_state=True)\n",
    "    _,encoder_h,encoder_c = encoder(encoder_input)\n",
    "    encoder_state = [encoder_h,encoder_c]\n",
    "\n",
    "    #decoder\n",
    "    decoder_input = Input(shape = (None, n_output))\n",
    "    decoder = CuDNNLSTM(n_units,return_sequences=True, return_state=True)\n",
    "    decoder_output, _, _ = decoder(decoder_input,initial_state=encoder_state)\n",
    "    decoder_dense = Dense(n_output,activation='softmax')\n",
    "    decoder_output = decoder_dense(decoder_output)\n",
    "\n",
    "    #生成的训练模型\n",
    "    model = Model([encoder_input,decoder_input],decoder_output)\n",
    "\n",
    "    #推理阶段，用于预测过程\n",
    "    encoder_infer = Model(encoder_input,encoder_state)\n",
    "\n",
    "    decoder_state_input_h = Input(shape=(n_units,))\n",
    "    decoder_state_input_c = Input(shape=(n_units,))    \n",
    "    decoder_state_input = [decoder_state_input_h, decoder_state_input_c]#上个时刻的状态h,c   \n",
    "\n",
    "    decoder_infer_output, decoder_infer_state_h, decoder_infer_state_c = decoder(decoder_input,initial_state=decoder_state_input)\n",
    "    decoder_infer_state = [decoder_infer_state_h, decoder_infer_state_c]#当前时刻得到的状态\n",
    "    decoder_infer_output = decoder_dense(decoder_infer_output)#当前时刻的输出\n",
    "    decoder_infer = Model([decoder_input]+decoder_state_input,[decoder_infer_output]+decoder_infer_state)\n",
    "\n",
    "    return model, encoder_infer, decoder_infer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T20:30:50.769766Z",
     "start_time": "2018-12-02T20:30:50.760452Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_chinese(source,encoder_inference, decoder_inference, n_steps, features):\n",
    "    #先通过推理encoder获得预测输入序列的隐状态\n",
    "    state = encoder_inference.predict(source)\n",
    "    #第一个字符'\\t',为起始标志\n",
    "    predict_seq = np.zeros((1,1,features))\n",
    "    predict_seq[0,0,target_dict['\\t']] = 1\n",
    "\n",
    "    output = ''\n",
    "    #开始对encoder获得的隐状态进行推理\n",
    "    #每次循环用上次预测的字符作为输入来预测下一次的字符，直到预测出了终止符\n",
    "    for i in range(n_steps):#n_steps为句子最大长度\n",
    "        #给decoder输入上一个时刻的h,c隐状态，以及上一次的预测字符predict_seq\n",
    "        yhat,h,c = decoder_inference.predict([predict_seq]+state)\n",
    "        #注意，这里的yhat为Dense之后输出的结果，因此与h不同\n",
    "        char_index = np.argmax(yhat[0,-1,:])\n",
    "        char = target_dict_reverse[char_index]\n",
    "        output += char\n",
    "        state = [h,c]#本次状态做为下一次的初始状态继续传递\n",
    "        predict_seq = np.zeros((1,1,features))\n",
    "        predict_seq[0,0,char_index] = 1\n",
    "        if char == '\\n':#预测到了终止符则停下来\n",
    "            break\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T20:30:52.650796Z",
     "start_time": "2018-12-02T20:30:51.304033Z"
    }
   },
   "outputs": [],
   "source": [
    "model, encoder_infer, decoder_infer = create_model(n_input=INPUT_FEATURE_LENGTH,\n",
    "                                                   n_output=OUTPUT_FEATURE_LENGTH,\n",
    "                                                   n_units=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T20:30:53.148595Z",
     "start_time": "2018-12-02T20:30:53.140074Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_33 (InputLayer)           (None, None, 75)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_34 (InputLayer)           (None, None, 3427)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_17 (CuDNNLSTM)       [(None, 1024), (None 4509696     input_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_18 (CuDNNLSTM)       [(None, None, 1024), 18239488    input_34[0][0]                   \n",
      "                                                                 cu_dnnlstm_17[0][1]              \n",
      "                                                                 cu_dnnlstm_17[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, None, 3427)   3512675     cu_dnnlstm_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 26,261,859\n",
      "Trainable params: 26,261,859\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T20:30:59.943967Z",
     "start_time": "2018-12-02T20:30:59.903915Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=rmsprop(),\n",
    "        metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T18:11:33.677915Z",
     "start_time": "2018-12-02T16:47:45.763543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16235 samples, validate on 4059 samples\n",
      "Epoch 1/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 1.1334 - acc: 0.0375 - val_loss: 1.8815 - val_acc: 0.0503\n",
      "Epoch 2/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 1.0330 - acc: 0.0535 - val_loss: 1.7581 - val_acc: 0.0573\n",
      "Epoch 3/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.9556 - acc: 0.0622 - val_loss: 1.6578 - val_acc: 0.0657\n",
      "Epoch 4/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.8960 - acc: 0.0683 - val_loss: 1.6080 - val_acc: 0.0726\n",
      "Epoch 5/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.8499 - acc: 0.0729 - val_loss: 1.5435 - val_acc: 0.0781\n",
      "Epoch 6/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.8134 - acc: 0.0770 - val_loss: 1.5219 - val_acc: 0.0819\n",
      "Epoch 7/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.7831 - acc: 0.0803 - val_loss: 1.5254 - val_acc: 0.0830\n",
      "Epoch 8/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.7574 - acc: 0.0829 - val_loss: 1.4831 - val_acc: 0.0863\n",
      "Epoch 9/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.7349 - acc: 0.0856 - val_loss: 1.5012 - val_acc: 0.0858\n",
      "Epoch 10/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.7146 - acc: 0.0878 - val_loss: 1.4507 - val_acc: 0.0906\n",
      "Epoch 11/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.6967 - acc: 0.0900 - val_loss: 1.4501 - val_acc: 0.0915\n",
      "Epoch 12/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.6797 - acc: 0.0920 - val_loss: 1.4640 - val_acc: 0.0907\n",
      "Epoch 13/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.6641 - acc: 0.0940 - val_loss: 1.4549 - val_acc: 0.0920\n",
      "Epoch 14/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.6492 - acc: 0.0957 - val_loss: 1.4580 - val_acc: 0.0921\n",
      "Epoch 15/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.6355 - acc: 0.0974 - val_loss: 1.4733 - val_acc: 0.0917\n",
      "Epoch 16/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.6222 - acc: 0.0993 - val_loss: 1.4777 - val_acc: 0.0925\n",
      "Epoch 17/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.6098 - acc: 0.1011 - val_loss: 1.4870 - val_acc: 0.0923\n",
      "Epoch 18/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.5976 - acc: 0.1027 - val_loss: 1.4889 - val_acc: 0.0928\n",
      "Epoch 19/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.5861 - acc: 0.1045 - val_loss: 1.4868 - val_acc: 0.0933\n",
      "Epoch 20/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5750 - acc: 0.1062 - val_loss: 1.5071 - val_acc: 0.0934\n",
      "Epoch 21/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5642 - acc: 0.1078 - val_loss: 1.5341 - val_acc: 0.0924\n",
      "Epoch 22/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5539 - acc: 0.1093 - val_loss: 1.5201 - val_acc: 0.0932\n",
      "Epoch 23/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5441 - acc: 0.1108 - val_loss: 1.5280 - val_acc: 0.0930\n",
      "Epoch 24/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5344 - acc: 0.1125 - val_loss: 1.5403 - val_acc: 0.0922\n",
      "Epoch 25/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.5254 - acc: 0.1141 - val_loss: 1.5501 - val_acc: 0.0927\n",
      "Epoch 26/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.5162 - acc: 0.1155 - val_loss: 1.5729 - val_acc: 0.0922\n",
      "Epoch 27/100\n",
      "16235/16235 [==============================] - 49s 3ms/step - loss: 0.5081 - acc: 0.1170 - val_loss: 1.5757 - val_acc: 0.0921\n",
      "Epoch 28/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4996 - acc: 0.1187 - val_loss: 1.5883 - val_acc: 0.0912\n",
      "Epoch 29/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4916 - acc: 0.1198 - val_loss: 1.5753 - val_acc: 0.0921\n",
      "Epoch 30/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4840 - acc: 0.1213 - val_loss: 1.5951 - val_acc: 0.0918\n",
      "Epoch 31/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.4764 - acc: 0.1228 - val_loss: 1.6240 - val_acc: 0.0911\n",
      "Epoch 32/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4697 - acc: 0.1239 - val_loss: 1.6190 - val_acc: 0.0908\n",
      "Epoch 33/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4627 - acc: 0.1253 - val_loss: 1.6242 - val_acc: 0.0910\n",
      "Epoch 34/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4563 - acc: 0.1266 - val_loss: 1.6419 - val_acc: 0.0908\n",
      "Epoch 35/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4498 - acc: 0.1277 - val_loss: 1.6628 - val_acc: 0.0906\n",
      "Epoch 36/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.4438 - acc: 0.1288 - val_loss: 1.6619 - val_acc: 0.0908\n",
      "Epoch 37/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4377 - acc: 0.1299 - val_loss: 1.6993 - val_acc: 0.0898\n",
      "Epoch 38/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4318 - acc: 0.1311 - val_loss: 1.6715 - val_acc: 0.0895\n",
      "Epoch 39/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4261 - acc: 0.1321 - val_loss: 1.6908 - val_acc: 0.0900\n",
      "Epoch 40/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4205 - acc: 0.1331 - val_loss: 1.7135 - val_acc: 0.0895\n",
      "Epoch 41/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.4151 - acc: 0.1342 - val_loss: 1.7306 - val_acc: 0.0898\n",
      "Epoch 42/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.4102 - acc: 0.1351 - val_loss: 1.7261 - val_acc: 0.0890\n",
      "Epoch 43/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.4050 - acc: 0.1360 - val_loss: 1.7329 - val_acc: 0.0894\n",
      "Epoch 44/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.4004 - acc: 0.1369 - val_loss: 1.7429 - val_acc: 0.0891\n",
      "Epoch 45/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3952 - acc: 0.1379 - val_loss: 1.7580 - val_acc: 0.0887\n",
      "Epoch 46/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.3909 - acc: 0.1386 - val_loss: 1.7502 - val_acc: 0.0885\n",
      "Epoch 47/100\n",
      "16235/16235 [==============================] - 52s 3ms/step - loss: 0.3865 - acc: 0.1394 - val_loss: 1.7683 - val_acc: 0.0882\n",
      "Epoch 48/100\n",
      "16235/16235 [==============================] - 52s 3ms/step - loss: 0.3822 - acc: 0.1403 - val_loss: 1.7603 - val_acc: 0.0888\n",
      "Epoch 49/100\n",
      "16235/16235 [==============================] - 52s 3ms/step - loss: 0.3783 - acc: 0.1410 - val_loss: 1.7677 - val_acc: 0.0879\n",
      "Epoch 50/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.3742 - acc: 0.1418 - val_loss: 1.8018 - val_acc: 0.0881\n",
      "Epoch 51/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3706 - acc: 0.1424 - val_loss: 1.7958 - val_acc: 0.0878\n",
      "Epoch 52/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3669 - acc: 0.1431 - val_loss: 1.7799 - val_acc: 0.0875\n",
      "Epoch 53/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3635 - acc: 0.1438 - val_loss: 1.8003 - val_acc: 0.0881\n",
      "Epoch 54/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3604 - acc: 0.1443 - val_loss: 1.8096 - val_acc: 0.0879\n",
      "Epoch 55/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3570 - acc: 0.1449 - val_loss: 1.8240 - val_acc: 0.0876\n",
      "Epoch 56/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3541 - acc: 0.1455 - val_loss: 1.8317 - val_acc: 0.0878\n",
      "Epoch 57/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3509 - acc: 0.1461 - val_loss: 1.8456 - val_acc: 0.0872\n",
      "Epoch 58/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3480 - acc: 0.1466 - val_loss: 1.8430 - val_acc: 0.0880\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.3451 - acc: 0.1470 - val_loss: 1.8585 - val_acc: 0.0867\n",
      "Epoch 60/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3422 - acc: 0.1476 - val_loss: 1.8575 - val_acc: 0.0863\n",
      "Epoch 61/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.3398 - acc: 0.1480 - val_loss: 1.8607 - val_acc: 0.0869\n",
      "Epoch 62/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3373 - acc: 0.1484 - val_loss: 1.8684 - val_acc: 0.0868\n",
      "Epoch 63/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3348 - acc: 0.1488 - val_loss: 1.8848 - val_acc: 0.0865\n",
      "Epoch 64/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3323 - acc: 0.1492 - val_loss: 1.8839 - val_acc: 0.0868\n",
      "Epoch 65/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3299 - acc: 0.1496 - val_loss: 1.8944 - val_acc: 0.0865\n",
      "Epoch 66/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3275 - acc: 0.1501 - val_loss: 1.8993 - val_acc: 0.0860\n",
      "Epoch 67/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.3252 - acc: 0.1503 - val_loss: 1.9076 - val_acc: 0.0865\n",
      "Epoch 68/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3231 - acc: 0.1508 - val_loss: 1.8966 - val_acc: 0.0867\n",
      "Epoch 69/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.3207 - acc: 0.1512 - val_loss: 1.9186 - val_acc: 0.0862\n",
      "Epoch 70/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.3188 - acc: 0.1515 - val_loss: 1.9054 - val_acc: 0.0866\n",
      "Epoch 71/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3168 - acc: 0.1517 - val_loss: 1.9207 - val_acc: 0.0865\n",
      "Epoch 72/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3148 - acc: 0.1520 - val_loss: 1.9242 - val_acc: 0.0864\n",
      "Epoch 73/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3129 - acc: 0.1524 - val_loss: 1.9414 - val_acc: 0.0865\n",
      "Epoch 74/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3111 - acc: 0.1526 - val_loss: 1.9248 - val_acc: 0.0861\n",
      "Epoch 75/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3091 - acc: 0.1528 - val_loss: 1.9287 - val_acc: 0.0861\n",
      "Epoch 76/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3075 - acc: 0.1531 - val_loss: 1.9488 - val_acc: 0.0860\n",
      "Epoch 77/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3058 - acc: 0.1534 - val_loss: 1.9386 - val_acc: 0.0854\n",
      "Epoch 78/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3041 - acc: 0.1537 - val_loss: 1.9569 - val_acc: 0.0858\n",
      "Epoch 79/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3026 - acc: 0.1539 - val_loss: 1.9584 - val_acc: 0.0852\n",
      "Epoch 80/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.3010 - acc: 0.1542 - val_loss: 1.9596 - val_acc: 0.0855\n",
      "Epoch 81/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2995 - acc: 0.1544 - val_loss: 1.9686 - val_acc: 0.0851\n",
      "Epoch 82/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2981 - acc: 0.1546 - val_loss: 1.9676 - val_acc: 0.0855\n",
      "Epoch 83/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2965 - acc: 0.1547 - val_loss: 1.9778 - val_acc: 0.0856\n",
      "Epoch 84/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2953 - acc: 0.1550 - val_loss: 1.9868 - val_acc: 0.0854\n",
      "Epoch 85/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2938 - acc: 0.1553 - val_loss: 1.9818 - val_acc: 0.0852\n",
      "Epoch 86/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2924 - acc: 0.1555 - val_loss: 1.9786 - val_acc: 0.0852\n",
      "Epoch 87/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2911 - acc: 0.1557 - val_loss: 1.9991 - val_acc: 0.0849\n",
      "Epoch 88/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2900 - acc: 0.1559 - val_loss: 1.9963 - val_acc: 0.0851\n",
      "Epoch 89/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2889 - acc: 0.1560 - val_loss: 1.9903 - val_acc: 0.0849\n",
      "Epoch 90/100\n",
      "16235/16235 [==============================] - 52s 3ms/step - loss: 0.2876 - acc: 0.1563 - val_loss: 2.0089 - val_acc: 0.0848\n",
      "Epoch 91/100\n",
      "16235/16235 [==============================] - 52s 3ms/step - loss: 0.2866 - acc: 0.1563 - val_loss: 2.0192 - val_acc: 0.0850\n",
      "Epoch 92/100\n",
      "16235/16235 [==============================] - 52s 3ms/step - loss: 0.2854 - acc: 0.1564 - val_loss: 2.0229 - val_acc: 0.0853\n",
      "Epoch 93/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2843 - acc: 0.1567 - val_loss: 2.0280 - val_acc: 0.0843\n",
      "Epoch 94/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2836 - acc: 0.1568 - val_loss: 2.0096 - val_acc: 0.0847\n",
      "Epoch 95/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2826 - acc: 0.1570 - val_loss: 2.0163 - val_acc: 0.0847\n",
      "Epoch 96/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2815 - acc: 0.1571 - val_loss: 2.0308 - val_acc: 0.0844\n",
      "Epoch 97/100\n",
      "16235/16235 [==============================] - 50s 3ms/step - loss: 0.2806 - acc: 0.1572 - val_loss: 2.0359 - val_acc: 0.0848\n",
      "Epoch 98/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2798 - acc: 0.1574 - val_loss: 2.0246 - val_acc: 0.0843\n",
      "Epoch 99/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2787 - acc: 0.1575 - val_loss: 2.0532 - val_acc: 0.0844\n",
      "Epoch 100/100\n",
      "16235/16235 [==============================] - 51s 3ms/step - loss: 0.2777 - acc: 0.1577 - val_loss: 2.0438 - val_acc: 0.0844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f455a646f28>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input,decoder_input],\n",
    "          y=decoder_output,\n",
    "          batch_size=64,\n",
    "          epochs=100,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T22:58:43.678528Z",
     "start_time": "2018-12-02T20:31:02.916143Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 1.1801 - acc: 0.0535\n",
      "I saw him playing baseball.\n",
      "我們為你的时候，我不知道。\n",
      "\n",
      "=============================================\n",
      "1\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.9735 - acc: 0.0765\n",
      "Why did you open the box?\n",
      "我們的父親很有趣。\n",
      "\n",
      "=============================================\n",
      "2\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.8870 - acc: 0.0859\n",
      "I come from England.\n",
      "我不知道他是什么。\n",
      "\n",
      "=============================================\n",
      "3\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.8302 - acc: 0.0919\n",
      "I've seen that.\n",
      "我不想要你。\n",
      "\n",
      "=============================================\n",
      "4\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.7836 - acc: 0.0973\n",
      "Where is the nearest station?\n",
      "我們在這裡很多次了。\n",
      "\n",
      "=============================================\n",
      "5\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.7385 - acc: 0.1032\n",
      "My hands and legs are swollen.\n",
      "我們的父母是一個很大的問題。\n",
      "\n",
      "=============================================\n",
      "6\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.6959 - acc: 0.1089\n",
      "Tom is a normal teenager.\n",
      "我不知道他的名字。\n",
      "\n",
      "=============================================\n",
      "7\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.6548 - acc: 0.1151\n",
      "Hurry up.\n",
      "我們在這裡的車子很得很快。\n",
      "\n",
      "=============================================\n",
      "8\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.6164 - acc: 0.1214\n",
      "Wait and see.\n",
      "我不知道我们在哪里。\n",
      "\n",
      "=============================================\n",
      "9\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.5817 - acc: 0.1275\n",
      "These are called shoes.\n",
      "我們在一起很快。\n",
      "\n",
      "=============================================\n",
      "10\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.5515 - acc: 0.1332\n",
      "Is he afraid of death?\n",
      "我不知道他是什麼意思。\n",
      "\n",
      "=============================================\n",
      "11\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.5259 - acc: 0.1379\n",
      "That's life.\n",
      "我們的車很有趣。\n",
      "\n",
      "=============================================\n",
      "12\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.5034 - acc: 0.1421\n",
      "They'll kill you.\n",
      "我不知道他的名字。\n",
      "\n",
      "=============================================\n",
      "13\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.4840 - acc: 0.1459\n",
      "These pants fit me well.\n",
      "我們不知道要做什麼。\n",
      "\n",
      "=============================================\n",
      "14\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.4684 - acc: 0.1485\n",
      "There's no way to know.\n",
      "我不想去那儿，他也不想。\n",
      "\n",
      "=============================================\n",
      "15\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.4546 - acc: 0.1510\n",
      "I can only speak for myself.\n",
      "我們在這裡做了什麼？\n",
      "\n",
      "=============================================\n",
      "16\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.4423 - acc: 0.1532\n",
      "I thought I was dreaming.\n",
      "我們的老師喜歡他的新車。\n",
      "\n",
      "=============================================\n",
      "17\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.4329 - acc: 0.1549\n",
      "Please put your shoes on.\n",
      "我們不能在這裡待很長時間。\n",
      "\n",
      "=============================================\n",
      "18\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 86s 4ms/step - loss: 0.4236 - acc: 0.1565\n",
      "Can you solve this problem?\n",
      "我們在這裡花了太多時間。\n",
      "\n",
      "=============================================\n",
      "19\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.4157 - acc: 0.1578\n",
      "My father grew old.\n",
      "我們在那裡有一個不愉快的經歷。\n",
      "\n",
      "=============================================\n",
      "20\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.4096 - acc: 0.1588\n",
      "He didn't listen to music.\n",
      "我不知道他是否已经为我做好了。\n",
      "\n",
      "=============================================\n",
      "21\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.4036 - acc: 0.1597\n",
      "We made friends with them.\n",
      "我們在這裡吃甚麼？\n",
      "\n",
      "=============================================\n",
      "22\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3975 - acc: 0.1605\n",
      "Give her the book.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "23\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3921 - acc: 0.1614\n",
      "You speak good English.\n",
      "我不喜欢那家。\n",
      "\n",
      "=============================================\n",
      "24\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3872 - acc: 0.1620\n",
      "Red is out of fashion.\n",
      "我不知道我是否有时间做。\n",
      "\n",
      "=============================================\n",
      "25\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3833 - acc: 0.1624\n",
      "Open your eyes, please.\n",
      "我不想再去那。\n",
      "\n",
      "=============================================\n",
      "26\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3797 - acc: 0.1627\n",
      "Maybe I should go help Tom.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "27\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3763 - acc: 0.1632\n",
      "You deserve the prize.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "28\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3735 - acc: 0.1635\n",
      "This is an important event.\n",
      "我不想再次去那儿。\n",
      "\n",
      "=============================================\n",
      "29\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3702 - acc: 0.1641\n",
      "You shouldn't wait here.\n",
      "我們在那裡上了公共汽車。\n",
      "\n",
      "=============================================\n",
      "30\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3677 - acc: 0.1645\n",
      "Is this jacket right for me?\n",
      "我不知道他們為什麼在打架。\n",
      "\n",
      "=============================================\n",
      "31\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3641 - acc: 0.1650\n",
      "This book is very thick.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "32\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3612 - acc: 0.1654\n",
      "Everybody had a hard time.\n",
      "我們在一次小咖啡做了。\n",
      "\n",
      "=============================================\n",
      "33\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3599 - acc: 0.1653\n",
      "Tom has been here since 2013.\n",
      "我不知道他們是否會離婚。\n",
      "\n",
      "=============================================\n",
      "34\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3581 - acc: 0.1655\n",
      "She went there yesterday.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "35\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3564 - acc: 0.1658\n",
      "I've been looking for you.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "36\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3546 - acc: 0.1660\n",
      "How can you do this to me?\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "37\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3524 - acc: 0.1665\n",
      "I saw the sunrise.\n",
      "我不知道他是否愛我。\n",
      "\n",
      "=============================================\n",
      "38\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3515 - acc: 0.1663\n",
      "Tom died three months ago.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "39\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3499 - acc: 0.1664\n",
      "We need your help.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "40\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3495 - acc: 0.1663\n",
      "He thinks he knows everything.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "41\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3472 - acc: 0.1669\n",
      "I have a pair of shoes.\n",
      "我不想再听到其他借口了。\n",
      "\n",
      "=============================================\n",
      "42\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3471 - acc: 0.1667\n",
      "Why aren't you listening?\n",
      "我不知道他是否已经为我做好了。\n",
      "\n",
      "=============================================\n",
      "43\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3466 - acc: 0.1666\n",
      "I'm a big football fan.\n",
      "我們在那裡有一個不愉快的經歷。\n",
      "\n",
      "=============================================\n",
      "44\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3464 - acc: 0.1667\n",
      "The boy is eating bread.\n",
      "我們在那裡抓了一些大魚。\n",
      "\n",
      "=============================================\n",
      "45\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3449 - acc: 0.1668\n",
      "You look very tired.\n",
      "我不知道他是否愛我。\n",
      "\n",
      "=============================================\n",
      "46\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3440 - acc: 0.1668\n",
      "Tom isn't dumb.\n",
      "我們在那裡上了公車汽車。\n",
      "\n",
      "=============================================\n",
      "47\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3422 - acc: 0.1671\n",
      "Dead men tell no tales.\n",
      "我們不能在這裡待很長時間。\n",
      "\n",
      "=============================================\n",
      "48\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3432 - acc: 0.1668\n",
      "I've got a lot more to learn.\n",
      "我不想再听到其他借口了。\n",
      "\n",
      "=============================================\n",
      "49\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3440 - acc: 0.1664\n",
      "How would you like your steak?\n",
      "我們在那裡有一個不愉快的。\n",
      "\n",
      "=============================================\n",
      "50\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3432 - acc: 0.1664\n",
      "Which book is better?\n",
      "我不想吃早餐。\n",
      "\n",
      "=============================================\n",
      "51\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 82s 4ms/step - loss: 0.3420 - acc: 0.1668\n",
      "Here is a letter for you.\n",
      "我不知道他是否愛我。\n",
      "\n",
      "=============================================\n",
      "52\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3424 - acc: 0.1666\n",
      "I feel very sick.\n",
      "我不知道他是否愛我。\n",
      "\n",
      "=============================================\n",
      "53\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3430 - acc: 0.1663\n",
      "Mary closed the door quietly.\n",
      "我不知道他是否已经为我做好。\n",
      "\n",
      "=============================================\n",
      "54\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3433 - acc: 0.1662\n",
      "Tom was on the list.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "55\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3439 - acc: 0.1660\n",
      "I'll think it over.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "56\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3446 - acc: 0.1655\n",
      "Her skin is smooth.\n",
      "我不知道他是谁。\n",
      "\n",
      "=============================================\n",
      "57\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3430 - acc: 0.1660\n",
      "It was a very stupid decision.\n",
      "我不知道我是否有时间做。\n",
      "\n",
      "=============================================\n",
      "58\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3462 - acc: 0.1654\n",
      "I'll bring wine.\n",
      "我不知道他是日本人。\n",
      "\n",
      "=============================================\n",
      "59\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3476 - acc: 0.1648\n",
      "I want an MP3 player!\n",
      "我不知道他是什么时候从法国回来的。\n",
      "\n",
      "=============================================\n",
      "60\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3454 - acc: 0.1654\n",
      "I wish we had won the game.\n",
      "我不知道他是日本人。\n",
      "\n",
      "=============================================\n",
      "61\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3475 - acc: 0.1648\n",
      "How about a sandwich?\n",
      "我們在學校前面見面了。\n",
      "\n",
      "=============================================\n",
      "62\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3442 - acc: 0.1655\n",
      "Tom gave me a pen.\n",
      "我不知道他是否已经为我做好了。\n",
      "\n",
      "=============================================\n",
      "63\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3450 - acc: 0.1651\n",
      "The letter was written by Tom.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "64\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3473 - acc: 0.1644\n",
      "He knows who they are.\n",
      "我不知道我們會到達哪裡。\n",
      "\n",
      "=============================================\n",
      "65\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3490 - acc: 0.1640\n",
      "I'll give you a book.\n",
      "我不知道她是否會來。\n",
      "\n",
      "=============================================\n",
      "66\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3485 - acc: 0.1642\n",
      "You should wear a coat.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "67\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3487 - acc: 0.1641\n",
      "You're very smart.\n",
      "我們在吃午餐。\n",
      "\n",
      "=============================================\n",
      "68\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3499 - acc: 0.1639\n",
      "Tom has only a week to decide.\n",
      "我不知道他是否已经为我做好了。\n",
      "\n",
      "=============================================\n",
      "69\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3494 - acc: 0.1640\n",
      "Let's begin.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "70\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3506 - acc: 0.1634\n",
      "I know that he was busy.\n",
      "我不知道他是什么时候从法国回来的。\n",
      "\n",
      "=============================================\n",
      "71\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3517 - acc: 0.1633\n",
      "She finally made it.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "72\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3509 - acc: 0.1632\n",
      "Do we have milk in the fridge?\n",
      "我不知道我們會到達哪裡。\n",
      "\n",
      "=============================================\n",
      "73\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3515 - acc: 0.1630\n",
      "She disappeared.\n",
      "我們在那裡有一個不愉快的經理。\n",
      "\n",
      "=============================================\n",
      "74\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3513 - acc: 0.1631\n",
      "He witnessed the murder.\n",
      "我們在那裡有一個不愉快的經到。\n",
      "\n",
      "=============================================\n",
      "75\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 86s 4ms/step - loss: 0.3543 - acc: 0.1622\n",
      "He was born in Nagasaki.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "76\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3541 - acc: 0.1624\n",
      "Tom wanted to see Mary.\n",
      "我們在那裡上了。\n",
      "\n",
      "=============================================\n",
      "77\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3538 - acc: 0.1625\n",
      "How should I know?\n",
      "我們在學校前面見面了。\n",
      "\n",
      "=============================================\n",
      "78\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3531 - acc: 0.1627\n",
      "Could you please repeat that?\n",
      "我不知道我是否有时间做。\n",
      "\n",
      "=============================================\n",
      "79\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3540 - acc: 0.1623\n",
      "He loves her.\n",
      "我不知道我們不是做什麼。\n",
      "\n",
      "=============================================\n",
      "80\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3557 - acc: 0.1618\n",
      "They don't pay me enough.\n",
      "我不知道他們為什麼。\n",
      "\n",
      "=============================================\n",
      "81\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3563 - acc: 0.1618\n",
      "I lost my umbrella.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "82\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3565 - acc: 0.1615\n",
      "Tom put some salt on his eggs.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "83\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3590 - acc: 0.1610\n",
      "Are you busy now?\n",
      "我不知道他是否已经为我一想的。\n",
      "\n",
      "=============================================\n",
      "84\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3580 - acc: 0.1612\n",
      "What are you looking at?\n",
      "我們在學校有一個早午餐。\n",
      "\n",
      "=============================================\n",
      "85\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3581 - acc: 0.1615\n",
      "We don't have any secrets.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "86\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3587 - acc: 0.1609\n",
      "Nobody wants you to do that.\n",
      "我不知道我是否有时间做。\n",
      "\n",
      "=============================================\n",
      "87\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3601 - acc: 0.1605\n",
      "Let's be realistic.\n",
      "我不知道他是什么时候。\n",
      "\n",
      "=============================================\n",
      "88\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3624 - acc: 0.1600\n",
      "Take it.\n",
      "我不知道我的手錶在哪裡。\n",
      "\n",
      "=============================================\n",
      "89\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3607 - acc: 0.1604\n",
      "The price is not reasonable.\n",
      "我不知道他是什么时候从法国回来的。\n",
      "\n",
      "=============================================\n",
      "90\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3617 - acc: 0.1602\n",
      "Tom is a clever kid.\n",
      "我們在那裡上了公共汽車。\n",
      "\n",
      "=============================================\n",
      "91\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3639 - acc: 0.1597\n",
      "He is a friendly person.\n",
      "我們在那裡上了太茶。\n",
      "\n",
      "=============================================\n",
      "92\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 86s 4ms/step - loss: 0.3628 - acc: 0.1598\n",
      "I'm innocent.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "93\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3632 - acc: 0.1598\n",
      "She sat on the bench.\n",
      "我不知道我們為怎麼做。\n",
      "\n",
      "=============================================\n",
      "94\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3635 - acc: 0.1596\n",
      "Don't forget about me.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "95\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3628 - acc: 0.1598\n",
      "He seems to be ill.\n",
      "我不知道他是什么时候我不会回来的。\n",
      "\n",
      "=============================================\n",
      "96\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 85s 4ms/step - loss: 0.3634 - acc: 0.1596\n",
      "I'm ready to leave.\n",
      "我不知道他是否已经为我做好。\n",
      "\n",
      "=============================================\n",
      "97\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3636 - acc: 0.1594\n",
      "We'll come back tomorrow.\n",
      "我們在這裡花了太晚時間。\n",
      "\n",
      "=============================================\n",
      "98\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 86s 4ms/step - loss: 0.3626 - acc: 0.1596\n",
      "I don't want to fail my exams.\n",
      "我不知道我是否有时间做。\n",
      "\n",
      "=============================================\n",
      "99\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3624 - acc: 0.1598\n",
      "Please allow me to go.\n",
      "我不知道他是否會來。\n",
      "\n",
      "=============================================\n",
      "100\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3661 - acc: 0.1588\n",
      "Please turn off the light.\n",
      "我們在吃晚餐。\n",
      "\n",
      "=============================================\n",
      "101\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3662 - acc: 0.1588\n",
      "Tom is more active.\n",
      "我不知道他是否愛我。\n",
      "\n",
      "=============================================\n",
      "102\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 83s 4ms/step - loss: 0.3663 - acc: 0.1588\n",
      "I'm the best.\n",
      "我不知道我們不能能做什麼。\n",
      "\n",
      "=============================================\n",
      "103\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3662 - acc: 0.1590\n",
      "I saw her enter the room.\n",
      "我們在這裡花了太多時間。\n",
      "\n",
      "=============================================\n",
      "104\n",
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 84s 4ms/step - loss: 0.3659 - acc: 0.1589\n",
      "Tom drank some juice.\n",
      "我不知道他是否愛我。\n",
      "\n",
      "=============================================\n",
      "105\n",
      "Epoch 1/1\n",
      " 5760/20294 [=======>......................] - ETA: 1:00 - loss: 0.3574 - acc: 0.1626"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-01c40a71ae1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.6-GPU/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/python3.6-GPU/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.6-GPU/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.6-GPU/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3.6-GPU/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1400\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for j in range(300):\n",
    "    print(j)\n",
    "    model.fit(x=[encoder_input,decoder_input],y=decoder_output,batch_size=None)\n",
    "    i= np.random.randint(10000)\n",
    "    print(input_texts[i])\n",
    "    test = encoder_input[i:i+1,:,:]\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    print(out)\n",
    "    print('=============================================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T20:14:36.557111Z",
     "start_time": "2018-12-02T20:14:36.521627Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Come in.\n",
      "我們在這裡花了太多時間。\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 2\n",
    "test = encoder_input[i:i+1,:,:]\n",
    "out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "print(input_texts[i])\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 将输入序列进行编码\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # 生成一个size=1的空序列\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # 将这个空序列的内容设置为开始字符\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # 进行字符恢复\n",
    "    # 简单起见，假设batch_size = 1\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # 退出条件：生成 \\n 或者 超过最大序列长度\n",
    "        if sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length :\n",
    "            stop_condition = True\n",
    "\n",
    "        # 更新target_seq\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # 更新中间状态\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence\n",
    "--------------------- \n",
    "作者：芥末的无奈 \n",
    "来源：CSDN \n",
    "原文：https://blog.csdn.net/weiwei9363/article/details/79464789 \n",
    "版权声明：本文为博主原创文章，转载请附上博文链接！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T04:18:39.657998Z",
     "start_time": "2018-12-02T04:18:39.652825Z"
    }
   },
   "source": [
    "# out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T03:09:22.414192Z",
     "start_time": "2018-12-02T03:09:22.410395Z"
    }
   },
   "outputs": [],
   "source": [
    "train_lstm = model.get_layer('cu_dnnlstm_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T03:10:24.234916Z",
     "start_time": "2018-12-02T03:10:24.225742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'cu_dnnlstm_5/kernel:0' shape=(75, 256) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00048403, -0.10057795,  0.09402207, ...,  0.06421671,\n",
       "         0.04817443, -0.04124532],\n",
       "       [ 0.02149276,  0.00541093,  0.11336602, ...,  0.12082654,\n",
       "        -0.11954425, -0.08038449],\n",
       "       [ 0.09851375, -0.12272102, -0.11307565, ..., -0.08199231,\n",
       "        -0.02517138, -0.02650847],\n",
       "       ...,\n",
       "       [ 0.06733374,  0.02784984,  0.02314961, ...,  0.09500158,\n",
       "         0.12246257,  0.00699327],\n",
       "       [-0.05950085, -0.10947321,  0.0575029 , ..., -0.01508953,\n",
       "        -0.04106094, -0.06283302],\n",
       "       [-0.11229177,  0.06529395, -0.0673771 , ..., -0.0839394 ,\n",
       "        -0.08219849,  0.09753321]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_lstm.weights[0])\n",
    "train_lstm.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T03:12:07.781604Z",
     "start_time": "2018-12-02T03:12:07.772280Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'cu_dnnlstm_5/kernel:0' shape=(75, 256) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00048403, -0.10057795,  0.09402207, ...,  0.06421671,\n",
       "         0.04817443, -0.04124532],\n",
       "       [ 0.02149276,  0.00541093,  0.11336602, ...,  0.12082654,\n",
       "        -0.11954425, -0.08038449],\n",
       "       [ 0.09851375, -0.12272102, -0.11307565, ..., -0.08199231,\n",
       "        -0.02517138, -0.02650847],\n",
       "       ...,\n",
       "       [ 0.06733374,  0.02784984,  0.02314961, ...,  0.09500158,\n",
       "         0.12246257,  0.00699327],\n",
       "       [-0.05950085, -0.10947321,  0.0575029 , ..., -0.01508953,\n",
       "        -0.04106094, -0.06283302],\n",
       "       [-0.11229177,  0.06529395, -0.0673771 , ..., -0.0839394 ,\n",
       "        -0.08219849,  0.09753321]], dtype=float32)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_lstm = encoder_infer.get_layer('cu_dnnlstm_5')\n",
    "print(infer_lstm.weights[0])\n",
    "infer_lstm.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-02T03:13:04.189914Z",
     "start_time": "2018-12-02T03:13:04.180336Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'cu_dnnlstm_5/kernel:0' shape=(75, 256) dtype=float32_ref>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00048537, -0.10057795,  0.09402207, ...,  0.06423962,\n",
       "         0.04818527, -0.04124521],\n",
       "       [ 0.02149243,  0.00541081,  0.11336623, ...,  0.12081587,\n",
       "        -0.11976563, -0.0803909 ],\n",
       "       [ 0.09846777, -0.12273928, -0.11309011, ..., -0.08199231,\n",
       "        -0.02517122, -0.02650827],\n",
       "       ...,\n",
       "       [ 0.06733384,  0.02784988,  0.02314961, ...,  0.09500158,\n",
       "         0.12246257,  0.00699364],\n",
       "       [-0.05950077, -0.10947321,  0.05750281, ..., -0.01508927,\n",
       "        -0.04100636, -0.06283302],\n",
       "       [-0.11229177,  0.06529395, -0.0673771 , ..., -0.0839394 ,\n",
       "        -0.08219849,  0.09753321]], dtype=float32)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infer_lstm = encoder_infer.get_layer('cu_dnnlstm_5')\n",
    "print(infer_lstm.weights[0])\n",
    "infer_lstm.get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-01T20:45:07.166702Z",
     "start_time": "2018-12-01T20:44:26.572314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "20294/20294 [==============================] - 40s 2ms/step - loss: 1.9426 - acc: 0.0410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f00aff7ce10>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=[encoder_input,decoder_output],y=decoder_input,batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "        loss='binary_crossentropy',\n",
    "        optimizer='adam',\n",
    "        metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1000,1210):\n",
    "    test = encoder_input[i:i+1,:,:]#i:i+1保持数组是三维\n",
    "    out = predict_chinese(test,encoder_infer,decoder_infer,OUTPUT_LENGTH,OUTPUT_FEATURE_LENGTH)\n",
    "    print(input_texts[i])\n",
    "    print(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.6-GPU",
   "language": "python",
   "name": "python3.6-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
